---
title: "R Notebook"
output: html_notebook
---

# Setup
```{r}
library(data.table)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

data <- fread(
  "example.txt",
  skip = 1,
  header = F,
  sep = "",
  col.names = "original"
)
```


# Tidying
```{r}
library(stringr)
library(tokenizers)

data[, c("index") := 1:.N, ]

rm_reg_1 <- "<.* .*>"
extr_reg <- "(.*), (.*) - (.*): (.*)"
data[, 
    c("original", "date", "time", "name", "text") := 
      as.list(str_match(original, extr_reg)),
      by = index
    ]
# remove specific patterns wa
data[, c("text") := gsub(rm_reg_1, "", .(text)), by = index]
data[, token := tokenize_words(text)]

```

# POS-Tags
```{r}
library(openNLP)
library(NLP)

sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator <- Maxent_POS_Tag_Annotator()

pos_tagger <- function(text) {
  if (is.na(text) || nchar(text) == 0) {
    return(NA)
  }
  a2 <- annotate(text, list(sent_token_annotator, word_token_annotator))
  annotate(text, pos_tag_annotator, a2)
}

data[, c("pos") := list(list(pos_tagger(.(text)))), by =.(index)]
```

# Language and stopwords
```{r}
library(cld3)
library(stopwords)

getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

language <- getmode(detect_language(data[, text]))
stopwords <- stopwords(language = language)
```

```{r}
data[, c("token_cl") := 
      ifelse(length(.(token)[[1]]) == 0, yes = NA, no = list(list(base::Filter(function(x) !(x %in% stopwords), unlist(.(token)))))),
   by = .(index)]
```

# Wordcloud
```{r}
library(wordcloud2)
frequent_terms <- freq_terms(data[, text], 100, stopwords = stopwords)

set.seed(1234)
pic <- wordcloud2(
  data = frequent_terms
)
pic 
```